{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Protein Atlas Image Classification\n",
    "\n",
    "to Jan 11, 2019\n",
    "\n",
    "class number : 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas     as pd\n",
    "import numpy      as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmyk_array_unify(ary_c, ary_m, ary_y, ary_k):\n",
    "    \n",
    "    # 一次元化して配列が同じか。\n",
    "    len_c = len(ary_c.reshape(-1,))\n",
    "    len_m = len(ary_m.reshape(-1,))\n",
    "    len_y = len(ary_y.reshape(-1,))\n",
    "    len_k = len(ary_k.reshape(-1,))\n",
    "\n",
    "    \n",
    "    if( len_c - len_m + len_y - len_k ) == 0 :\n",
    "       cmyk = []\n",
    "       \n",
    "       d_y_2 = len(ary_c)\n",
    "       d_x_2 = len(ary_c[0])\n",
    "       \n",
    "       for i in range(d_y_2):\n",
    "           d_x_3 = []\n",
    "           for j in range(d_x_2):\n",
    "               d_z_3 = []\n",
    "               d_z_3.append(ary_c[i][j])\n",
    "               d_z_3.append(ary_m[i][j])\n",
    "               d_z_3.append(ary_y[i][j])\n",
    "               d_z_3.append(ary_k[i][j])\n",
    "               d_x_3.append(d_z_3)\n",
    "           cmyk.append(d_x_3)\n",
    "       return np.array(cmyk)\n",
    "       \n",
    "    else:\n",
    "       print(\"配列の長さが違う。\")\n",
    "       return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hpaic_image_loader(img_name, folder=\"./data/train/\", resize=(128,128), dim_1 = True):\n",
    "    \"\"\"\n",
    "    image loading and unifying as 3-level tensor\n",
    "    \"\"\"\n",
    "    img_blue   = cv2.resize(cv2.imread( folder + img_name + \"_blue\"   + \".png\", 0), dsize = resize)\n",
    "    img_green  = cv2.resize(cv2.imread( folder + img_name + \"_green\"  + \".png\", 0), dsize = resize)\n",
    "    img_red    = cv2.resize(cv2.imread( folder + img_name + \"_red\"    + \".png\", 0), dsize = resize)\n",
    "    img_yellow = cv2.resize(cv2.imread( folder + img_name + \"_yellow\" + \".png\", 0), dsize = resize)\n",
    "    \n",
    "    if dim_1:\n",
    "        return cmyk_array_unify(img_blue, img_green, img_red, img_yellow).reshape(-1,)\n",
    "        \n",
    "    return cmyk_array_unify(img_blue, img_green, img_red, img_yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def o_train_test_split(x_array, y_array, ratio=0.7):\n",
    "    \"\"\"\n",
    "    rand\n",
    "    \"\"\"\n",
    "    x_train_len         = int( len(x_array) * ratio )\n",
    "    x_train_index_array = random.sample(range(0, len(x_array), 1), k = x_train_len)\n",
    "    x_test_index_array  = list(set(range(0, len(x_array), 1)) - set(x_train_index_array))\n",
    "    x_train_array       = [x_array[i] for i in x_train_index_array]\n",
    "    x_test_array        = [x_array[i] for i in x_test_index_array]\n",
    "    y_train_array       = [y_array[i] for i in x_train_index_array]\n",
    "    y_test_array        = [y_array[i] for i in x_test_index_array]\n",
    "    \n",
    "    return (x_train_array, x_test_array, y_train_array, y_test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    " \n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2,2, 1],\n",
    "                        strides=[1,2,2, 1], padding='SAME')\n",
    "\n",
    "def max_pool_4x4(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 4,4, 1],\n",
    "                        strides=[1,4,4, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_val(y_step_2, t_step_2):\n",
    "    length = len(y_step_2)\n",
    "    f_array = []\n",
    "    for index in range(length):\n",
    "        TP = sum([1 if (a_step == 1 and b_step == 1) else 0 for a_step, b_step in zip(y_step_2[index], t_step_2[index])])\n",
    "        FP = sum([1 if (a_step == 1 and b_step == 0) else 0 for a_step, b_step in zip(y_step_2[index], t_step_2[index])])\n",
    "        FN = sum([1 if (a_step == 0 and b_step == 1) else 0 for a_step, b_step in zip(y_step_2[index], t_step_2[index])])\n",
    "        f_array.append( TP / ( TP + ( FP + FN ) / 2 ))\n",
    "    return f_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "### Data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yの読み出し（最初の9個）\n",
    "train_df = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_id\n",
    "image_name = np.array(train_df[\"Id\"][:])\n",
    "\n",
    "# target_vector\n",
    "t_data = np.array(train_df.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_name_array, X_test_name_array, y_train_array, y_test_array = o_train_test_split(image_name, t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size       = 500\n",
    "x_train_name_len = len(X_train_name_array)\n",
    "batch_count      = int(x_train_name_len / batch_size) # 21750 / 50 = 435\n",
    "batch_count_mod  = x_train_name_len % batch_size      # 21750 % 50 = 72\n",
    "\n",
    "# randomにindexの値がとられる。[29800, 23100, 26200, 4800, 28800, 13800, 27100, 11200,]\n",
    "b_top_index_array = random.sample(range(0, x_train_name_len, batch_size), k = batch_count-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3500, 3000, 9500, 20500, 17000, 19000, 6500, 19500, 14000, 1000, 13500, 11000, 16000, 9000, 8000, 2500, 12500, 500, 6000, 13000, 5000, 15000, 18000, 17500, 18500, 16500, 15500, 7500, 4000, 12000, 5500, 10500, 2000, 8500, 0, 7000, 10000, 20000, 11500, 14500, 4500, 21000]\n",
      "21500\n"
     ]
    }
   ],
   "source": [
    "print(b_top_index_array)\n",
    "print((batch_count) * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 他クラス分類問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_y = np.array([[0.2, 0.9, 0.2, 0.9, 0],[0.2, 0.9, 0.2, 0.9, 0],[0.2, 0.9, 0.2, 0.9, 0.8]])\n",
    "# sample_t = np.array([[0.1, 0.2, 0.8, 0.9, 0.6],[0.1, 0.2, 0.8, 0.9, 0.6],[0.5, 0.2, 0.8, 0.9, 0.3]])\n",
    "\n",
    "\n",
    "# 出てくる配列 y = 0 ~ -1 [[0,0,10.8,],[],[],[],[]]\n",
    "\n",
    "# F値を求めて、tf.reduce_mean する。この段階で、a = [0~1]×入力値数（バッチ数）\n",
    "#accuracy = tf.reduce_mean(tf.cast(a, \"float\"))\n",
    "\n",
    "\n",
    "# まずは誤差関数がちゃんと動くか確認\n",
    "# tensor →rリストとりだし\n",
    "# リスト計算→tensor\n",
    "# tensorflow でf値を求めるやつがあるか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### マルチクラス分類問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "# 入力層\n",
    "x = tf.placeholder(\"float\", [None, 65536])\n",
    "\n",
    "# 形状変更\n",
    "x_image = tf.reshape(x, [-1, 128, 128, 4])\n",
    "\n",
    "# 第1層 (バッチ正規化層)\n",
    "y_norm1 = tf.contrib.layers.batch_norm(x_image)\n",
    "\n",
    "# 第2層 (畳み込み層)\n",
    "W_conv1 = weight_variable([3, 3, 4, 8])\n",
    "b_conv1 = bias_variable([8])\n",
    "y_conv1 = tf.nn.relu(conv2d(y_norm1, W_conv1) + b_conv1)\n",
    "\n",
    "# 第3層 (バッチ正規化層)\n",
    "y_norm2 = tf.contrib.layers.batch_norm(y_conv1)\n",
    "\n",
    "# 第4層 (畳み込み層)\n",
    "W_conv2 = weight_variable([3, 3, 8, 8])\n",
    "b_conv2 = bias_variable([8])\n",
    "y_conv2 = tf.nn.relu(conv2d(y_norm2, W_conv2) + b_conv2)\n",
    "\n",
    "# 第5層 (バッチ正規化層)\n",
    "y_norm3 = tf.contrib.layers.batch_norm(y_conv2)\n",
    "\n",
    "# 第6層 (畳み込み層)\n",
    "W_conv3 = weight_variable([3, 3, 8, 16])\n",
    "b_conv3 = bias_variable([16])\n",
    "y_conv3 = tf.nn.relu(conv2d(y_norm3, W_conv3) + b_conv3)\n",
    "\n",
    "# 第7層 (バッチ正規化層)\n",
    "y_norm4 = tf.contrib.layers.batch_norm(y_conv3)\n",
    "\n",
    "# 第8層 (プーリング層)\n",
    "y_pool1 = max_pool_2x2(y_norm4) #64*64\n",
    "y_drop1 = tf.nn.dropout(y_pool1, keep_prob)\n",
    "\n",
    "# 第9層 (畳み込み層)\n",
    "W_conv4 = weight_variable([3, 3, 16, 32])\n",
    "b_conv4 = bias_variable([32])\n",
    "y_conv4 = tf.nn.relu(conv2d(y_drop1, W_conv4) + b_conv4)\n",
    "\n",
    "# 第10層 (バッチ正規化層)\n",
    "y_norm5 = tf.contrib.layers.batch_norm(y_conv4)\n",
    "\n",
    "# 第11層 (プーリング層)\n",
    "y_pool2 = max_pool_2x2(y_norm5) #32*32\n",
    "y_drop2 = tf.nn.dropout(y_pool2, keep_prob)\n",
    "\n",
    "# 第12層 (畳み込み層)\n",
    "W_conv5 = weight_variable([3, 3, 32, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "y_conv5 = tf.nn.relu(conv2d(y_drop2, W_conv5) + b_conv5)\n",
    "\n",
    "# 第13層 (バッチ正規化層)\n",
    "y_norm6 = tf.contrib.layers.batch_norm(y_conv5)\n",
    "\n",
    "# 第14層 (プーリング層)\n",
    "y_pool3 = max_pool_2x2(y_norm6) #16*16\n",
    "y_drop3 = tf.nn.dropout(y_pool3, keep_prob)\n",
    "\n",
    "# 第15層 (畳み込み層)\n",
    "W_conv6 = weight_variable([3, 3, 64, 128])\n",
    "b_conv6 = bias_variable([128])\n",
    "y_conv6 = tf.nn.relu(conv2d(y_drop3, W_conv6) + b_conv6)\n",
    "\n",
    "# 第16層 (バッチ正規化層)\n",
    "y_norm7 = tf.contrib.layers.batch_norm(y_conv6)\n",
    "\n",
    "\n",
    "# 第17層 (プーリング層)\n",
    "y_pool4 = max_pool_2x2(y_norm7) #8*8\n",
    "y_drop4 = tf.nn.dropout(y_pool4, keep_prob)\n",
    "\n",
    "# 第18層 (畳み込み層)\n",
    "W_conv7 = weight_variable([3, 3, 128, 256])\n",
    "b_conv7 = bias_variable([256])\n",
    "y_conv7 = tf.nn.relu(conv2d(y_drop4, W_conv7) + b_conv7)\n",
    "\n",
    "# 第19層 (バッチ正規化層)\n",
    "y_norm8 = tf.contrib.layers.batch_norm(y_conv7)\n",
    "\n",
    "# 第20層 (プーリング層)\n",
    "y_pool5 = max_pool_2x2(y_norm8) #4*4\n",
    "y_drop5 = tf.nn.dropout(y_pool5, keep_prob)\n",
    "\n",
    "# 第21層 (平坦化層)\n",
    "y_pool2_flat = tf.reshape(y_drop5, [-1, 4096])\n",
    " \n",
    "# 第22層 (全結合層)\n",
    "W_fc1 = weight_variable([4096, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "y_fc1 = tf.nn.relu(tf.matmul(y_pool2_flat, W_fc1) + b_fc1)\n",
    " \n",
    "# 第23層 (全結合層)\n",
    "W_fc2 = weight_variable([1024, 28])\n",
    "b_fc2 = bias_variable([28])\n",
    "y = tf.sigmoid(tf.matmul(y_fc1, W_fc2) + b_fc2) #<= シグモイド関数\n",
    " \n",
    "# 目標出力の次元\n",
    "t = tf.placeholder(\"float\", [None, 28])\n",
    "\n",
    "# 損失関数を計算グラフを作成する\n",
    "# cross_entropy = -tf.reduce_sum(t * tf.log(y))\n",
    "# cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=t,logits=y)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum( t * tf.log(y + 1e-9)) + ((1-t) * tf.log(1 - y + 1e-9)  )\n",
    "\n",
    "# 次の(1)、(2)を行うための計算グラフを作成する。\n",
    "# (1) 損失関数に対するネットワークを構成するすべての変数の勾配を計算する。\n",
    "# (2) 勾配方向に学習率分移動して、すべての変数を更新する。\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    " \n",
    "# 初期化を行うための計算グラフを作成する。\n",
    "init_g = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    " \n",
    "# テストデータに対する正答率を計算するための計算グラフを作成する。\n",
    "\n",
    "# correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "# f1_score, update_op = tf.contrib.metrics.f1_score(t, y)\n",
    "\n",
    "\n",
    "# y_f = tf.cast(y, \"float\")\n",
    "# t_f = tf.cast(t, \"float\")\n",
    "# tp = tf.math.reduce_sum(tf.count_nonzero(y_f * t_f), 0)\n",
    "# tn = tf.math.reduce_sum(tf.count_nonzero((y_f - 1.) * (t_f - 1.)), 0)\n",
    "# fp = tf.math.reduce_sum(tf.count_nonzero(y_f * (t_f - 1.)), 0)\n",
    "# fn = tf.math.reduce_sum(tf.count_nonzero((y_f - 1.) * t_f), 0)\n",
    "\n",
    "\n",
    "# # acc       = (tp + tn) / (tp + fp + fn + tn)\n",
    "# # precision = tp / (tp + fp)\n",
    "# # recall    = tp / (tp + fn)\n",
    "# # fmeasure  = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "# p = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "# r = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "# f1 = 2*p*r / (p+r+tf.keras.backend.epsilon())\n",
    "# f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "\n",
    "# f_score  = 1 - tf.reduce_mean(f1)\n",
    "\n",
    "# # tf_f1 = tf_f1_score(t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/42 [00:00<?, ?it/s]\n",
      "  2%|█▉                                                                                 | 1/42 [00:26<17:56, 26.27s/it]\n",
      "  5%|███▉                                                                               | 2/42 [00:48<16:46, 25.17s/it]\n",
      "  7%|█████▉                                                                             | 3/42 [01:11<15:56, 24.52s/it]\n",
      " 10%|███████▉                                                                           | 4/42 [01:35<15:19, 24.20s/it]\n",
      " 12%|█████████▉                                                                         | 5/42 [01:58<14:47, 24.00s/it]\n",
      " 14%|███████████▊                                                                       | 6/42 [02:22<14:23, 23.99s/it]\n",
      " 17%|█████████████▊                                                                     | 7/42 [02:46<13:54, 23.85s/it]\n",
      " 19%|███████████████▊                                                                   | 8/42 [03:10<13:30, 23.84s/it]\n",
      " 21%|█████████████████▊                                                                 | 9/42 [03:33<13:06, 23.83s/it]\n",
      " 24%|███████████████████▌                                                              | 10/42 [03:57<12:42, 23.81s/it]\n",
      " 26%|█████████████████████▍                                                            | 11/42 [04:22<12:29, 24.17s/it]\n",
      " 29%|███████████████████████▍                                                          | 12/42 [04:46<12:01, 24.05s/it]\n",
      " 31%|█████████████████████████▍                                                        | 13/42 [05:10<11:35, 23.99s/it]\n",
      " 33%|███████████████████████████▎                                                      | 14/42 [05:35<11:17, 24.21s/it]\n",
      " 36%|█████████████████████████████▎                                                    | 15/42 [05:59<10:56, 24.32s/it]\n",
      " 38%|███████████████████████████████▏                                                  | 16/42 [06:23<10:31, 24.28s/it]\n",
      " 40%|█████████████████████████████████▏                                                | 17/42 [06:47<10:01, 24.07s/it]\n",
      " 43%|███████████████████████████████████▏                                              | 18/42 [07:11<09:36, 24.04s/it]\n",
      " 45%|█████████████████████████████████████                                             | 19/42 [07:36<09:22, 24.46s/it]\n",
      " 48%|███████████████████████████████████████                                           | 20/42 [08:00<08:56, 24.37s/it]\n",
      " 50%|█████████████████████████████████████████                                         | 21/42 [08:25<08:31, 24.36s/it]\n",
      " 52%|██████████████████████████████████████████▉                                       | 22/42 [08:49<08:04, 24.24s/it]\n",
      " 55%|████████████████████████████████████████████▉                                     | 23/42 [09:14<07:47, 24.61s/it]\n",
      " 57%|██████████████████████████████████████████████▊                                   | 24/42 [09:38<07:17, 24.30s/it]\n",
      " 60%|████████████████████████████████████████████████▊                                 | 25/42 [10:02<06:51, 24.18s/it]\n",
      " 62%|██████████████████████████████████████████████████▊                               | 26/42 [10:26<06:26, 24.15s/it]\n",
      " 64%|████████████████████████████████████████████████████▋                             | 27/42 [10:50<06:01, 24.09s/it]\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 28/42 [11:14<05:35, 23.98s/it]\n",
      " 69%|████████████████████████████████████████████████████████▌                         | 29/42 [11:38<05:12, 24.06s/it]\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 30/42 [12:02<04:49, 24.12s/it]\n",
      " 74%|████████████████████████████████████████████████████████████▌                     | 31/42 [12:26<04:23, 23.97s/it]\n",
      " 76%|██████████████████████████████████████████████████████████████▍                   | 32/42 [12:49<03:58, 23.87s/it]\n",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 33/42 [13:13<03:35, 23.91s/it]\n",
      " 81%|██████████████████████████████████████████████████████████████████▍               | 34/42 [13:38<03:12, 24.11s/it]\n",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 35/42 [14:02<02:48, 24.06s/it]\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 36/42 [14:25<02:23, 23.92s/it]\n",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 37/42 [14:50<02:00, 24.03s/it]\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▏       | 38/42 [15:14<01:36, 24.09s/it]\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▏     | 39/42 [15:37<01:11, 23.91s/it]\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████    | 40/42 [16:02<00:48, 24.11s/it]\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████  | 41/42 [16:26<00:24, 24.02s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [16:49<00:00, 23.92s/it]\n",
      " 50%|█████████████████████████████████████████                                         | 1/2 [16:49<16:49, 1009.98s/it]\n",
      "  0%|                                                                                           | 0/42 [00:00<?, ?it/s]\n",
      "  2%|█▉                                                                                 | 1/42 [00:24<16:28, 24.12s/it]\n",
      "  5%|███▉                                                                               | 2/42 [00:48<16:02, 24.06s/it]\n",
      "  7%|█████▉                                                                             | 3/42 [01:11<15:34, 23.96s/it]\n",
      " 10%|███████▉                                                                           | 4/42 [01:36<15:18, 24.18s/it]\n",
      " 12%|█████████▉                                                                         | 5/42 [02:01<15:02, 24.39s/it]\n",
      " 14%|███████████▊                                                                       | 6/42 [02:25<14:37, 24.38s/it]\n",
      " 17%|█████████████▊                                                                     | 7/42 [02:50<14:16, 24.48s/it]\n",
      " 19%|███████████████▊                                                                   | 8/42 [03:14<13:48, 24.37s/it]\n",
      " 21%|█████████████████▊                                                                 | 9/42 [03:38<13:17, 24.17s/it]\n",
      " 24%|███████████████████▌                                                              | 10/42 [04:04<13:10, 24.70s/it]\n",
      " 26%|█████████████████████▍                                                            | 11/42 [04:28<12:46, 24.73s/it]\n",
      " 29%|███████████████████████▍                                                          | 12/42 [04:53<12:21, 24.70s/it]\n",
      " 31%|█████████████████████████▍                                                        | 13/42 [05:18<11:56, 24.69s/it]\n",
      " 33%|███████████████████████████▎                                                      | 14/42 [05:41<11:19, 24.26s/it]\n",
      " 36%|█████████████████████████████▎                                                    | 15/42 [06:05<10:48, 24.04s/it]\n",
      " 38%|███████████████████████████████▏                                                  | 16/42 [06:28<10:21, 23.92s/it]\n",
      " 40%|█████████████████████████████████▏                                                | 17/42 [06:51<09:52, 23.69s/it]\n",
      " 43%|███████████████████████████████████▏                                              | 18/42 [07:14<09:24, 23.53s/it]\n",
      " 45%|█████████████████████████████████████                                             | 19/42 [07:37<08:56, 23.34s/it]\n",
      " 48%|███████████████████████████████████████                                           | 20/42 [08:01<08:33, 23.34s/it]\n",
      " 50%|█████████████████████████████████████████                                         | 21/42 [08:24<08:08, 23.28s/it]\n",
      " 52%|██████████████████████████████████████████▉                                       | 22/42 [08:47<07:44, 23.24s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████▉                                     | 23/42 [09:10<07:22, 23.29s/it]\n",
      " 57%|██████████████████████████████████████████████▊                                   | 24/42 [09:33<06:57, 23.18s/it]\n",
      " 60%|████████████████████████████████████████████████▊                                 | 25/42 [09:57<06:35, 23.25s/it]\n",
      " 62%|██████████████████████████████████████████████████▊                               | 26/42 [10:21<06:17, 23.62s/it]\n",
      " 64%|████████████████████████████████████████████████████▋                             | 27/42 [10:45<05:55, 23.71s/it]\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 28/42 [11:11<05:39, 24.26s/it]\n",
      " 69%|████████████████████████████████████████████████████████▌                         | 29/42 [11:35<05:17, 24.42s/it]\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 30/42 [12:01<04:57, 24.76s/it]\n",
      " 74%|████████████████████████████████████████████████████████████▌                     | 31/42 [12:25<04:29, 24.46s/it]\n",
      " 76%|██████████████████████████████████████████████████████████████▍                   | 32/42 [12:48<04:01, 24.12s/it]\n",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 33/42 [13:12<03:35, 23.98s/it]\n",
      " 81%|██████████████████████████████████████████████████████████████████▍               | 34/42 [13:36<03:12, 24.09s/it]\n",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 35/42 [14:00<02:47, 23.97s/it]\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 36/42 [14:24<02:23, 23.91s/it]\n",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 37/42 [14:49<02:01, 24.22s/it]\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▏       | 38/42 [15:12<01:36, 24.09s/it]\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▏     | 39/42 [15:37<01:12, 24.15s/it]\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████    | 40/42 [16:02<00:48, 24.47s/it]\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████  | 41/42 [16:27<00:24, 24.62s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [16:51<00:00, 24.40s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [33:41<00:00, 1010.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# セッションを作成して、計算グラフを実行する。\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    # 初期化を実行する。\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    \n",
    "    \n",
    "   \n",
    "    # 学習を実行する。（エポック）\n",
    "    for i in tqdm(range(2)):\n",
    "        # ミニパッチ\n",
    "        for p_index in tqdm(b_top_index_array):\n",
    "            # 最後の配列だった場合\n",
    "            if p_index == batch_count * batch_size:\n",
    "                index_array = list(range(p_index, p_index + batch_count_mod )) #　-１いらない？(とった)\n",
    "            else:\n",
    "                index_array = list(range(p_index, p_index + batch_size))\n",
    "            \n",
    "            # ここで読み出し。\n",
    "            patch_x = [hpaic_image_loader(X_train_name_array[i]) for i in index_array]\n",
    "            patch_t = [y_train_array[i] for i in index_array]\n",
    "            \n",
    "            sess.run(train_step, feed_dict={x: patch_x, t: patch_t, keep_prob: 0.5})\n",
    "\n",
    "\n",
    "\n",
    "             \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, \"C:/Users/talla/Dropbox/Computer/Repositry/Self/human-protein-atlas/model_3/hpaic_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Restore and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/talla/Dropbox/Computer/Repositry/Self/human-protein-atlas/model_3/hpaic_model\n",
      "Restored a model\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init_g)\n",
    "sess.run(init_l)\n",
    "saver = tf.train.import_meta_graph('./model_3/hpaic_model.meta')\n",
    "saver.restore(sess,  tf.train.latest_checkpoint('./model_3/'))\n",
    "print('Restored a model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yの読み出し（最初の9個）\n",
    "sub_df = pd.read_csv(\"./data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 20.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 22.90it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 21.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 21.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 21.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 20.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 19.84it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 21.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 23.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 21.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 22.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 22.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 21.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:23<00:00, 21.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:24<00:00, 20.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 702/702 [00:33<00:00, 21.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# 名前の読み出し。\n",
    "sub_image_name  = np.array(sub_df[\"Id\"][:])\n",
    "\n",
    "size        = 500\n",
    "length      = len(sub_image_name)\n",
    "count       = int(length / size) # 21750 / 500 = 43\n",
    "count_mod   = length % size      # 21750 % 500 = 250\n",
    "\n",
    "pred_test = []\n",
    "for i in range(count):\n",
    "    s_index = i*size\n",
    "    e_index = i*size+ size\n",
    "    \n",
    "    if i == count -1:\n",
    "        e_index = e_index + count_mod\n",
    "    \n",
    "    sub_image_array = np.array([hpaic_image_loader(j, \"./data/test/\" ) for j in tqdm(sub_image_name[s_index : e_index])])\n",
    "    pred_test.extend(sess.run(y, feed_dict={x: sub_image_array, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1 if j>=0.5 else 0 for  j in i]for i in pred_test]\n",
    "index_array = [[ str(j) if i[j] else \" \"  for j in range(len(i)) ]for i in a]\n",
    "string_array = [[ j for j in i if j != \" \"]for i in index_array]\n",
    "join_array = [' '.join(i) for i in string_array]\n",
    "submit = pd.DataFrame({\"Id\":sub_image_name, \"Predicted\":join_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"submit/submit_1.csv\" , columns=['Id',\"Predicted\" ], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflowのgpu動作確認●\n",
    "# テストデータの評価\n",
    "# 答えの出力（方法、形式、確認）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataとtrain_dataで訓練\n",
    "X_train, X_test,y_train, y_test = train_test_split(x_data, t_data, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31072/31072 [4:32:11<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# yをもとにxを読み出し。(_blue, _green, _red, _yellow)でテンソル３階層する。\n",
    "cmyk = [\"_blue\",\"_green\",\"_red\",\"_yellow\"]\n",
    "x_list = []\n",
    "\n",
    "for img in tqdm(image_name):\n",
    "    img_blue   = cv2.imread( \"./data/train/\" + img + \"_blue\"   + \".png\", 0)\n",
    "    img_green  = cv2.imread( \"./data/train/\" + img + \"_green\"  + \".png\", 0)\n",
    "    img_red    = cv2.imread( \"./data/train/\" + img + \"_red\"    + \".png\", 0)\n",
    "    img_yellow = cv2.imread( \"./data/train/\" + img + \"_yellow\" + \".png\", 0)\n",
    "    \n",
    "    cmyk       = cmyk_array_unify(img_blue, img_green, img_red, img_yellow)\n",
    "    cmyk_plane = cmyk.reshape(-1,)\n",
    "    x_list.append(cmyk_plane)\n",
    "    \n",
    "x_data = np.array(x_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape_17:0\", shape=(3,), dtype=int32)\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'DecodePng_17:0' shape=(?, ?, 3) dtype=uint8>>\n",
      "Tensor(\"ToFloat_4:0\", shape=(?, ?, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "image_r = tf.read_file(\"/data/train/00ab10d6-bba4-11e8-b2b9-ac1f6b6435d0_blue.png\")\n",
    "image = tf.image.decode_png(image_r, channels=3)\n",
    "image_float = tf.to_float(image)\n",
    "print(tf.shape(image))\n",
    "print(image.get_shape)\n",
    "print(image_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41 45 34 ...  0  0  0]\n",
      " [43 50 44 ...  0  0  0]\n",
      " [42 46 51 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sessionの作成\n",
    "\n",
    "\"\"\"\n",
    "#　訓練データの読み込み\n",
    "np.set_printoptions(threshold=10)\n",
    "img = cv2.imread(\"./data/train/00ab10d6-bba4-11e8-b2b9-ac1f6b6435d0_blue.png\",0)\n",
    "print(img)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_c = np.array([[\"a\",\"b\",\"c\"],[\"d\",\"e\",\"f\"]])\n",
    "z_m = np.array([[\"g\",\"h\",\"i\"],[\"j\",\"k\",\"l\"]])\n",
    "z_y = np.array([[\"m\",\"n\",\"o\"],[\"p\",\"q\",\"r\"]])\n",
    "z_k = np.array([[\"s\",\"t\",\"u\"],[\"v\",\"w\",\"x\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['a' 'g' 'm' 's']\n",
      "  ['b' 'h' 'n' 't']\n",
      "  ['c' 'i' 'o' 'u']]\n",
      "\n",
      " [['d' 'j' 'p' 'v']\n",
      "  ['e' 'k' 'q' 'w']\n",
      "  ['f' 'l' 'r' 'x']]]\n"
     ]
    }
   ],
   "source": [
    "s = cmyk_array_unify(z_c,z_m,z_y,z_k)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a' 'g' 'm' ... 'l' 'r' 'x']\n"
     ]
    }
   ],
   "source": [
    "x_image = s.reshape(-1,)\n",
    "print(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コードの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3786672106358165647, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6674410373\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2611446402891614919\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu動作確認コード\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(262144,), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dataの読み込み\n",
    "\n",
    "train_labels = pd.read_csv(\"data/train_original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = tf.Variable(tf.zeros([2,1])) #入力は２次元\n",
    "#     b = tf.Variable(tf.zeros([1]))   #入力は２次元\n",
    "\n",
    "#     # def y(x):\n",
    "#     #     return sigmoid(np.dot(w,x)+b)\n",
    "#     # def sigmoid(x):\n",
    "#     #     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 512]) #入力\n",
    "t = tf.placeholder(tf.float32, shape=[None, 1]) #正解出力\n",
    "y = tf.nn.sigmoid(tf.matmul(x,w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-6aef72370c84>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\talla\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\talla\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\talla\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\talla\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\talla\\Anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "x_batch, t_batch = mnist.train.next_batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.12156864 0.21960786 0.6\n",
      " 0.7686275  0.9960785  0.8196079  0.6039216  0.60784316 0.6039216\n",
      " 0.5529412  0.21960786 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.227451   0.69803923 0.77647066\n",
      " 0.56078434 0.9176471  0.9921569  0.9803922  0.9921569  0.95294124\n",
      " 0.95294124 0.9803922  0.9921569  0.9921569  0.9921569  0.9921569\n",
      " 0.36078432 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.35686275 0.9921569  0.9921569  0.9921569  0.9921569  0.79215693\n",
      " 0.34901962 0.21176472 0.34509805 0.         0.         0.23529413\n",
      " 0.34901962 0.34901962 0.34901962 0.34901962 0.15294118 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.0509804  0.8117648  0.98823535\n",
      " 0.91372555 0.9450981  0.34901962 0.0627451  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.43137258 0.9921569  0.91372555 0.         0.1254902\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.43137258\n",
      " 0.9921569  0.91372555 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.43137258 0.9921569  0.91372555\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.43137258 0.9921569  0.9607844  0.28235295 0.15686275\n",
      " 0.04313726 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.28627452\n",
      " 0.9921569  0.9921569  0.9921569  0.9921569  0.82745105 0.54509807\n",
      " 0.23529413 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00392157 0.37254903 0.8745099\n",
      " 0.9333334  0.9921569  0.9921569  0.9921569  0.98823535 0.74509805\n",
      " 0.5803922  0.07450981 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07843138 0.13333334 0.19215688\n",
      " 0.4784314  0.8000001  0.9803922  0.9921569  0.9921569  0.7803922\n",
      " 0.07450981 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.14117648 0.6431373  0.9921569  0.9921569  0.80392164 0.07843138\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.03137255\n",
      " 0.3254902  0.9921569  0.9921569  0.3529412  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.00784314 0.7490196\n",
      " 0.9921569  0.90196085 0.07843138 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.43529415 0.9921569  0.9921569\n",
      " 0.11764707 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.14117648 0.7725491  0.9921569  0.9058824  0.07843138 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.05490196 0.44705886 0.9490197  0.9960785\n",
      " 0.9843138  0.3137255  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3254902\n",
      " 0.6431373  0.35686275 0.2509804  0.04313726 0.3529412  0.5686275\n",
      " 0.8352942  0.9921569  0.9921569  0.9921569  0.3529412  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3647059  0.9921569  0.9960785\n",
      " 0.9843138  0.96470594 0.9921569  0.9921569  0.9960785  0.9921569\n",
      " 0.6901961  0.18431373 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01176471 0.4666667  0.94117653 0.9921569  0.9921569\n",
      " 0.9921569  0.77647066 0.6        0.21960786 0.04313726 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(x_batch[0])\n",
    "print(t_batch[0])\n",
    "print(type(x_batch[0]))\n",
    "print(type(t_batch[0]))\n",
    "\n",
    "#print(t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-c6070b6cb362>:3: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    img = sess.run(image)\n",
    "    Image.fromarray(np.uint8(img)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = np.array(data.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2150555571929651621, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6871947673\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3101695577045397688\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpuenv)",
   "language": "python",
   "name": "conda_tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
